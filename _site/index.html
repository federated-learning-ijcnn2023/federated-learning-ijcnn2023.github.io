<!DOCTYPE html>
<html lang="">
  
  <head>
  <meta charset="UTF-8">
  <title>Federated Learning<br/>Methods, Applications, Challenges, and beyond</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="/ijcnn-flss-2023/css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/ijcnn-flss-2023/css/cayman.css">
</head>

  <body>
    <section class="page-header">
  <h1 class="project-name">Federated Learning<br/>Methods, Applications, Challenges, and beyond</h1>
  <h2 class="project-tagline">IJCNN 2023 Special Session</h2>
</section>

    <section class="main-content">
      
      <p align="center">
  <a href="https://2023.ijcnn.org/">
    <img src="./logo_ss_ijcnn2023.png" />
  </a>
</p>

<h2 id="aim-and-scope">Aim and Scope</h2>

<p>Due to data isolation and privacy challenges in the real world, Federated Learning stands out among various AI technologies for real-world scenarios, ranging from business applications like risk evaluation systems in finance to drug discovery in life sciences. Although still in its infancy, FL has already shown significant theoretical and practical results, making it one of the hottest topics in the machine learning community. Nonetheless, many questions and challenges remain open and attract increasing interest from international research communities: e.g., the statistical unbalancing of data, distributed optimization problems, communication latency, security, and resilience to attack issues. In particular, the trustworthiness of FL systems is threatened by adversarial attacks against data privacy, the learning algorithm’s stability, and the system’s confidentiality. Such vulnerabilities are exacerbated by the distributed training in federated learning, which makes protecting against threats harder and makes it evident the need to further the research on defense methods to make federated learning a real solution for a trustworthy system.</p>

<p>The main objective of the 2023 Special Session on Federated Learning - Methods, Applications, Challenges, and beyond, hosted at the IEEE International Joint Conference on Neural Networks (IJCNN), is to focus the international research community’s attention on the emerging perspectives and practical algorithms in Federated Learning, with a particular emphasis on its privacy and security aspects. This session aims to collect novel contributions and research experiences from the variegated research communities participating in the IJCNN conference. We believe that such diversity will help in finding novel approaches for mitigating current issues and optimize Federated Learning algorithms.</p>

<p>The main outcomes of the first editions of this special session, held in the previous editions of IJCNN, include a renewed interest in the challenges posed by FL, the proposals of solutions to main issues related to Federated Learning, and the creation of research collaborations between researchers from different communities. We are then very happy to propose once again this special session, so to facilitate sharing new findings and advances with past participants and new researchers.</p>

<h2 id="topics">Topics</h2>

<p>This special session welcomes contributions about all aspects of federated learning, with a special focus on its intersection with trustworthy AI.</p>

<ul>
  <li>Algorithmic/theoretical advances, novel issues, and open challenges in Federated Learning</li>
  <li>Other non-functional properties of FL (e.g., fairness, interpretability/explainability, personalization, …)</li>
  <li>Federated Learning variants and Decentralized Federated Learning (e.g., vertical federated learning, split learning, gossip learning, …)</li>
  <li>Federated Learning with non-iid data distributions</li>
  <li>Performance Evaluation Methods, Metrics, and Tools of Federated Learning Systems</li>
  <li>Other applications of FL (e.g., FL for IoT, FL for healthcare, FL on edge devices, advertising, social network, blockchain, web search, …)</li>
  <li>Tools and resources (e.g., benchmark datasets, software libraries, …)</li>
  <li>Trustworthy issues in different stages of FL (Data processing, model training, deployment)</li>
  <li>Security in Federated Learning (e.g., data leakage, cryptography-based attack/defense, hardware-based defense, …)</li>
  <li>Privacy aspects of Federated Learning (e.g., privacy leakage, differential privacy, secure multi-party computation, …)</li>
  <li>Robustness of Federated Learning (e.g., data Heterogeneity, byzantine, targeted, and backdoor attacks, …)</li>
</ul>

<h2 id="important-dates">Important Dates</h2>

<ul>
  <li><strong>Paper submission: January 31, 2023</strong></li>
  <li>Notification of acceptance: March 31, 2023</li>
</ul>

<p><a href="https://edas.info/N30081">Submission system</a></p>

<h2 id="organizers">Organizers</h2>
<ul>
  <li>
    <p>Dr. Mirko Polato, Department of Computer Science, University of Turin, Italy<br />
mirko.polato@unito.it</p>
  </li>
  <li>
    <p>Prof. Zenglin Xu, Harbin Institute of Technology, Shenzhen and Peng Cheng Lab, China<br />
zenglin@gmail.com</p>
  </li>
  <li>
    <p>Dr. Fiammetta Marulli, Department of Maths and Physics, University of Campania, Italy<br />
fiammetta.marulli@unicampania.it</p>
  </li>
  <li>
    <p>Porf. Roberto Esposito, Department of Computer Science, University of Turin, Italy<br />
roberto.esposito@unito.it</p>
  </li>
  <li>
    <p>Prof. Irwin King, The Chinese University of Hong Kong, Hong Kong<br />
irwinking@gmail.com</p>
  </li>
</ul>


      <footer class="site-footer">
  <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
</footer>


    </section>

  </body>
</html>
